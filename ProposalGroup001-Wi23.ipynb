{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Duy Vu\n",
    "- Lexu (Gavin) Zhao\n",
    "- Tianyi Bian\n",
    "- Tunan Li"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "Our goal is to design and execute a machine-learning model that estimates room occupancy based on temperature, light, sound, CO2, and digital passive infrared (PIR) data. We will use data provided by UCI, which consists of 10,129 instances and 16 attributes. The data was collected in a 6m - 4.6m room with seven sensor nodes and one edge node in a star configuration. The sensor nodes transmit data every 30 seconds to measure changes in a room over 3 days. Amongst the 7 sensors, 4 of them are able to measure temperature, light, and sound simultaneous, 1 is able to measure CO2 and CO2 change, and 2 is able to measure movement based on PIR.  Hence we have 4*3+2+2=16 variables in our final dataset. To generate an accurate model predicting room occupancy, we will use Decision Tree and use Random Forest as our performance benchmark. Because decision trees are insensitive to data normalization, we do not need to further normalize the data. But we might still need to do feature selection if needed. By executing this project, we hope to accurately estimate room occupancy, which can be used to optimize energy consumption and improve building management. We will measure the performance of the two models by comparing the F1-score and the confusion matrix evaluated using 10-fold cross-validation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "In recent years, there has been a growing interest in developing smart and energy-efficient buildings. One important aspect of building management is the efficient use of resources, including energy consumption. Occupancy-based control is a popular strategy for optimizing energy usage in buildings. By accurately estimating the number of occupants in a room, building managers can adjust heating, cooling, and lighting systems to meet the occupants' needs while minimizing energy waste. \n",
    "Research on occupancy-based control using machine learning has been active in recent years. Many studies have proposed and evaluated various models and algorithms for predicting occupancy based on sensor data. For instance, the study conducted by Wang et al. (2019) <a name=\"cite1\" href=\"https://www.sciencedirect.com/science/article/pii/S0926580518302656\"><sup>[1]</sup></a> used SVM and Random Forest models to estimate occupancy based on temperature and humidity sensor data. The study carried out a 30-day experiment in a library and utilized data mining techniques to model occupancy patterns. As a result, the heating, ventilation, and air conditioning (HVAC) systems were able to achieve better performance. Another research is from Adarsh et al. (2020)<a name=\"cite2\" href=\"https://web2py.iiit.ac.in/research_centres/publications/view_publication/mastersthesis/872\"><sup>[2]</sup></a> that studies the sensor data analytics and data reduction techniques. The research discussed occupancy estimation using ML, analysis of ML algorithms from the perspective of constrained microcontrollers, and ML-based data transmission reduction for occupancy applications. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "This project aims to develop a machine-learning model that accurately estimates and predicts the number of people in a room using a dataset collected at different times throughout 4 days from various types of sensors, including those that detect temperature, light, sound, CO2, and PIR, respectively. It’s contributional in solving the task of monitoring room occupancy in real-time. To achieve this goal, our machine learning algorithm, based on the methods of logistic regression or decision trees, will be trained and tested using a large dataset of sensor measurements collected from real-world scenarios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Room Occupancy Estimation Data Set: \n",
    "- Link: https://archive.ics.uci.edu/ml/datasets/Room+Occupancy+Estimation\n",
    "- Reference: Data collected by Adarsh Pal Singh (IIIT Hyderabad, India), Dr. Sachin Chaudhari (IIIT Hyderabad, India)\n",
    "- Size of the dataset: 16 variables, 10130 observations\n",
    "- An observation consists with the specified time during the period of 4 days and the readout values from five different types of non-intrusive sensors that measure temperature (4 sensors), light (4 sensors), sound (4 sensors), CO2 (2 sensors) and digital passive infrared (2 sensors). The ground-truth value of a number of occupancies is also included. The variables listed below are considered to be critical, and they are represented in terms of numerical values with units labeled: temperature in degrees Celsius, light in Lux, sound in Volts (read by ADC devices), and Carbon Dioxide in PPM.\n",
    "- Since each type of sensor includes multiple devices, we need to combine those numerous read-out data into a specific output value by weighted averaging, and clean up the outliers or null cells from the table due to the potential noises that are not related to the targeted room.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>S1_Temp</th>\n",
       "      <th>S2_Temp</th>\n",
       "      <th>S3_Temp</th>\n",
       "      <th>S4_Temp</th>\n",
       "      <th>S1_Light</th>\n",
       "      <th>S2_Light</th>\n",
       "      <th>S3_Light</th>\n",
       "      <th>S4_Light</th>\n",
       "      <th>S1_Sound</th>\n",
       "      <th>S2_Sound</th>\n",
       "      <th>S3_Sound</th>\n",
       "      <th>S4_Sound</th>\n",
       "      <th>S5_CO2</th>\n",
       "      <th>S5_CO2_Slope</th>\n",
       "      <th>S6_PIR</th>\n",
       "      <th>S7_PIR</th>\n",
       "      <th>Room_Occupancy_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017/12/22</td>\n",
       "      <td>10:49:41</td>\n",
       "      <td>24.94</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.56</td>\n",
       "      <td>25.38</td>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>390</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017/12/22</td>\n",
       "      <td>10:50:12</td>\n",
       "      <td>24.94</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.56</td>\n",
       "      <td>25.44</td>\n",
       "      <td>121</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>390</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017/12/22</td>\n",
       "      <td>10:50:42</td>\n",
       "      <td>25.00</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.50</td>\n",
       "      <td>25.44</td>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>390</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017/12/22</td>\n",
       "      <td>10:51:13</td>\n",
       "      <td>25.00</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.56</td>\n",
       "      <td>25.44</td>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>390</td>\n",
       "      <td>0.388462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017/12/22</td>\n",
       "      <td>10:51:44</td>\n",
       "      <td>25.00</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.56</td>\n",
       "      <td>25.44</td>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>390</td>\n",
       "      <td>0.253846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>2018/01/11</td>\n",
       "      <td>08:58:07</td>\n",
       "      <td>25.06</td>\n",
       "      <td>25.13</td>\n",
       "      <td>24.69</td>\n",
       "      <td>25.31</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>2018/01/11</td>\n",
       "      <td>08:58:37</td>\n",
       "      <td>25.06</td>\n",
       "      <td>25.06</td>\n",
       "      <td>24.69</td>\n",
       "      <td>25.25</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>2018/01/11</td>\n",
       "      <td>08:59:08</td>\n",
       "      <td>25.13</td>\n",
       "      <td>25.06</td>\n",
       "      <td>24.69</td>\n",
       "      <td>25.25</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10127</th>\n",
       "      <td>2018/01/11</td>\n",
       "      <td>08:59:39</td>\n",
       "      <td>25.13</td>\n",
       "      <td>25.06</td>\n",
       "      <td>24.69</td>\n",
       "      <td>25.25</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10128</th>\n",
       "      <td>2018/01/11</td>\n",
       "      <td>09:00:09</td>\n",
       "      <td>25.13</td>\n",
       "      <td>25.06</td>\n",
       "      <td>24.69</td>\n",
       "      <td>25.25</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10129 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Time  S1_Temp  S2_Temp  S3_Temp  S4_Temp  S1_Light  \\\n",
       "0      2017/12/22  10:49:41    24.94    24.75    24.56    25.38       121   \n",
       "1      2017/12/22  10:50:12    24.94    24.75    24.56    25.44       121   \n",
       "2      2017/12/22  10:50:42    25.00    24.75    24.50    25.44       121   \n",
       "3      2017/12/22  10:51:13    25.00    24.75    24.56    25.44       121   \n",
       "4      2017/12/22  10:51:44    25.00    24.75    24.56    25.44       121   \n",
       "...           ...       ...      ...      ...      ...      ...       ...   \n",
       "10124  2018/01/11  08:58:07    25.06    25.13    24.69    25.31         6   \n",
       "10125  2018/01/11  08:58:37    25.06    25.06    24.69    25.25         6   \n",
       "10126  2018/01/11  08:59:08    25.13    25.06    24.69    25.25         6   \n",
       "10127  2018/01/11  08:59:39    25.13    25.06    24.69    25.25         6   \n",
       "10128  2018/01/11  09:00:09    25.13    25.06    24.69    25.25         6   \n",
       "\n",
       "       S2_Light  S3_Light  S4_Light  S1_Sound  S2_Sound  S3_Sound  S4_Sound  \\\n",
       "0            34        53        40      0.08      0.19      0.06      0.06   \n",
       "1            33        53        40      0.93      0.05      0.06      0.06   \n",
       "2            34        53        40      0.43      0.11      0.08      0.06   \n",
       "3            34        53        40      0.41      0.10      0.10      0.09   \n",
       "4            34        54        40      0.18      0.06      0.06      0.06   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10124         7        33        22      0.09      0.04      0.06      0.08   \n",
       "10125         7        34        22      0.07      0.05      0.05      0.08   \n",
       "10126         7        34        22      0.11      0.05      0.06      0.08   \n",
       "10127         7        34        22      0.08      0.08      0.10      0.08   \n",
       "10128         7        34        22      0.08      0.05      0.06      0.08   \n",
       "\n",
       "       S5_CO2  S5_CO2_Slope  S6_PIR  S7_PIR  Room_Occupancy_Count  \n",
       "0         390      0.769231       0       0                     1  \n",
       "1         390      0.646154       0       0                     1  \n",
       "2         390      0.519231       0       0                     1  \n",
       "3         390      0.388462       0       0                     1  \n",
       "4         390      0.253846       0       0                     1  \n",
       "...       ...           ...     ...     ...                   ...  \n",
       "10124     345      0.000000       0       0                     0  \n",
       "10125     345      0.000000       0       0                     0  \n",
       "10126     345      0.000000       0       0                     0  \n",
       "10127     345      0.000000       0       0                     0  \n",
       "10128     345      0.000000       0       0                     0  \n",
       "\n",
       "[10129 rows x 19 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Occupancy_Estimation.csv')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "A tentative solution to solve this problem is to adopt a decision tree classification model.The decision tree works by splitting on available features and using greedy search to find the best split which will maximize entropy gain and create the most homogenous splits. We use decision trees because decision trees have good interpretability. We know the exact parameters at each split and we can tell which variable contributes more to the final decision. This information is useful because, in real life, we don't want to have too many sensors in one room just for predicting how many people are in a room due to cost considerations. Finding which sensor contributes most to prediction can help us reduce the number of unnecessary sensors.More importantly, since we are interested in predicting the number of people in our room, we want our model to classify our data points into 4 different categories and generate 4 different labels representing the number of people in the room.(Room with 0 people, room with 1 person, room with 2 people, and room with 3 people).Therefore, using a decision tree, capable of separating multiple classes and outputting multiple labels at one time, will be a good option. The nature of our dataset also suggests using a Decision tree.By inspecting our dataset, it looks like most of our variables are sensor measurements which are numerical and different measurements, such as light measurement and temperature measurement, seem to have quite different ranges and don’t seem like they are normalized previously. Therefore, by using a decision tree, which is a nonparametric approach, we don’t need to worry about normalizations. The sklearn document suggests that the inbound sklearn class DecisionTreeClassifier utilizes the CART tree, which only supports numerical data. Therefore, as our measurements are numerical, we can easily implement a decision tree just using basic sklearn and we are almost guaranteed success on model creation. \n",
    "\n",
    "For the benchmark model, we propose using Random Forest, which is similar to decision trees but needs more time to train as it combines the result of multiple decision trees and Random Forest typically achieves better performance than a single tree. By implementing the Random Forest algorithm, we want to figure out if it's worth spending extra time to train for the Random Forest by comparing the performance of two models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Because we are doing a data classification, which is a classification problem, then the most appropriate error metrics are related to how many classifications we made on the test data are right or not; in other words, we have to avoid misclassification as much as possible. As we will use logistic regression in our model to predict the probability of data containing 0,1,2,3 people in total. We are going to use the recall: which is the true positive rate, which is the P(detect positive | true positive), and this equals to P(detect positive and true positive)/P(true positive), and we want this probability as closer to one as possible for a good model. Another error metric we use is the specificity, which calculates the probability of having correct negative labels. Mathematically,  P(detect negative | true negative), which is equivalent to P(detect negative and true negative)/P(true negative).\n",
    "\n",
    "We want to maximize the presicion since we care a lot if a person detected positive is positive. But in our case, we don’t have special weight on either side of the positive/negative, this is why we care about the both true posibve rate and true negative rate equally. We will use these metrics into either One vs One or One vs Rest to validate if our model is solid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One ethical problem it may raise is that it is the case the people who don’t move will highly likely be ignored by the motion detector. For example, a disabled person who doesn’t move will have low motion data, and it is easy for us to misclassify it as a room has no people, but in fact, they are classified as real people. This may seem offensive to them.\n",
    "\n",
    "\n",
    "Additionally, after our model is trained well and has low test error and generation error, our model may be misused by a person who illegally wants to pry on others, since some people may don’t want others to know if they appear in a room, and most pries are illegal.\n",
    "\n",
    "\n",
    "Lastly, we have to think about security issues: when bad thieves use our model to detect how many people are there in an apartment, it may give them ideas about when to come in. In other words, if our model has predicted that none of the people in the room, this may provide opportunities for illegal actions such as theft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As a team, its is important to have regular team meetings to discuss progress, challenges, and updates. This provides an opportunity for team members to share their thoughts and ideas and provide feedback.\n",
    "* We also realize that there may be conflicts (for instance, some want to use model A and some want to use model B instead, and both come up with concise and logical reasons). In this case, we will ask for advice from the professor and TAs to make sure that all of us are in the good track. For difficulty, we can do the same thing: actively participate in the office hour and lectures to give us the opportunity to overcome the difficulties.\n",
    "* When making the decision, we will do a plural mode of the vote, and the same for setting goals and schedule, Regular check-ins can help ensure that everyone is on track and adjustments can be made as soon as possible.\n",
    "* Each team member should have a clear understanding of their responsibilities and workload. It's important to set each individual the same amount of time and work to make sure that we are going to finish on time, and starting early is important for us. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Task |\n",
    "|---|---|---|\n",
    "| 2/18  | 7 PM  | Group member introudction and Project kickoff |\n",
    "| 2/20  | 7 PM  | Discuss project goals and divide tasks to each team members, Research on potential topics and select useful datasets, Review and finalize the selection |\n",
    "| 2/22  | Morning  | Project Proposal Submission Deadline |\n",
    "| 2/29  | 7 PM  | Discuss and choose appropriate and efficienty ML models, start building and training the selected ML models, Review progress and look for any issues appearing|\n",
    "| 3/7  | 7 PM  | Checkpoint Write-up: Preliminary results including feature detection performance, learning or validation curves for model, etc. |\n",
    "| 3/8  | Morning  | Checkpoint Submission Deadline |\n",
    "| 3/15  | 7 PM  | Continue building and training ML models, Evaluate model performance and refine as needed, Prepare project presentation and finalize code |\n",
    "| 3/22  | Before 11:59 PM | Final Project Submission Deadline, and Team Evaluation Survey  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Wang, Wei, et al. \"Occupancy prediction through machine learning and data fusion of environmental sensing and Wi-Fi sensing in buildings.\" Energy and Buildings, vol. 177, 2018, pp. 14-26, doi: 10.1016/j.enbuild.2018.07.003.<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Singh, Adarsh Pal. \"Machine Learning for IoT Applications: Sensor Data Analytics and Data Reduction Techniques.\" IIIT/TH/2020/64, advisor: Sachin Chaudhari, 30 June 2020.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
